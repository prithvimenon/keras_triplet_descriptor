{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy_baseline.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "scylC1qNuBY0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Baseline Code\n",
        "\n",
        "This code introduces a two-step training for the N-HPatches problem. In N-HPatches problem, we aim to generate a patch descriptor that is able to perform successfully tasks such as matching, retrieval or verification. \n",
        "\n",
        "Contrary to classical HPatches dataset, in N-HPatches, images contain random non-smooth perturbations produced by a synthetic noise. This noise could be critical when training the descriptor, therefore, we introduce a denoising model that could help us to deal with those perturbations. Denoising models have been already introduced in the course [tutorials](https://github.com/MatchLab-Imperial/deep-learning-course) and lectures, their objective is to generate a clean/denoised version of the input image.  We will refer in this code to the images with noise as `noisy`, to the images after applying the denoise model as `denoised` and the original patches from HPatches (so no extra noise added) which are used as ground-truth for the denoising step as `clean`. \n",
        "\n",
        "\n",
        "Thus, we aim to minimize the noise in images before the second step, which is computing a feature vector, also called descriptor. Those descriptions must be a powerful representation of the input patches. The idea behind is that if two descriptors belong two similar patches, they should be close to each other, i.e. have a low Euclidean distance. See figure below:\n",
        "\n",
        "![](https://i.ibb.co/4tvm3Vh/descriptorspace.png)\n",
        "\n",
        "This baseline code gives a method you can use to compare to whatever another approach you develop.  There are several other approaches you can test to see if there is any improvement, e.g. train the descriptor directly with noisy patches, without the denoising model. However, this code provides some guidance about how to implement the different blocks, how to stack them if desired, how to read the data and how to evaluate the method.\n",
        "\n",
        "The values given can be improved without changing the core method, only by tuning correctly the hyperparameters or giving it more training time, among others.\n",
        "\n",
        "As a first step of the project, you should get familiar with the problem and the provided code, so you can develop more complex and robust algorithms afterward. "
      ]
    },
    {
      "metadata": {
        "id": "iamuRgeiNLjW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Safety Check\n",
        "\n",
        "As Google Colab is an external platform, we cannot guarantee that everytime you connect to a remote server, you will have the same amount of RAM or video RAM. For that reason, we will first check the amount of memory we have in the notebook. RAM should be around 12.9 GB, which is enough to load the datasets in memory. Also, usually, we have available 11.4 GB of GPU memory, which is more than enough to run this code. However, some users reported having only 500 MB of GPU memory. If you have that amount, restart the environment to see if you get the corresponding 11.4 GB."
      ]
    },
    {
      "metadata": {
        "id": "ZZG4BqkENEyd",
        "colab_type": "code",
        "outputId": "51ca32c3-2579-47ea-ebdc-b120b8e41e11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "cell_type": "code",
      "source": [
        "# Taken from\n",
        "# https://stackoverflow.com/questions/48750199/google-colaboratory-misleading-information-about-its-gpu-only-5-ram-available\n",
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# Colab only provides one GPU and it is not always guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python2.7/dist-packages (0.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BBvIvBoyg68g",
        "colab_type": "code",
        "outputId": "3dc75687-96b1-4ca3-f208-37726c7e0828",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "printm()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('RAM Free: 12.9 GB', ' | Proc size: 151.9 MB')\n",
            "GPU RAM Free: 11441MB | Used: 0MB | Util   0% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OMiynJ7p-zI8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Downloading Functions and Data\n",
        "\n",
        "The first step is to clone the GitHub repository of the course, which contains already implemented functions. You can use your own function and import them here doing the same. In addition, we are going to download and extract the N-HPatches data. \n",
        "\n",
        "As a note, in colab, we can run terminal commands by using ```!```. Also, by using ```%``` we have access to the [built-in IPython magic commands](https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-cd), which we will use to move through directories (`cd` command). It takes around 5 minutes to download and unzip the dataset. \n"
      ]
    },
    {
      "metadata": {
        "id": "yV1m-9ZGuKGj",
        "colab_type": "code",
        "outputId": "17c59e03-5209-41ff-ad6e-26d3f94c181c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "# Clone repo\n",
        "!git clone https://github.com/MatchLab-Imperial/keras_triplet_descriptor"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'keras_triplet_descriptor'...\n",
            "remote: Enumerating objects: 178, done.\u001b[K\n",
            "remote: Total 178 (delta 0), reused 0 (delta 0), pack-reused 178\u001b[K\n",
            "Receiving objects: 100% (178/178), 149.87 MiB | 10.62 MiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n",
            "Checking out files: 100% (69/69), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pyZSqhZ5LACT",
        "colab_type": "code",
        "outputId": "ba578715-aa80-4d19-b0d1-753182f03256",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Change directory\n",
        "%cd /content/keras_triplet_descriptor    \n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/keras_triplet_descriptor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "307CBCL-FjX4",
        "colab_type": "code",
        "outputId": "e1e14622-71fd-48d2-db58-28af953324fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        }
      },
      "cell_type": "code",
      "source": [
        "# Download data\n",
        "!wget -O hpatches_data.zip https://imperialcollegelondon.box.com/shared/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-14 14:29:11--  https://imperialcollegelondon.box.com/shared/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n",
            "Resolving imperialcollegelondon.box.com (imperialcollegelondon.box.com)... 107.152.24.197, 107.152.25.197\n",
            "Connecting to imperialcollegelondon.box.com (imperialcollegelondon.box.com)|107.152.24.197|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip [following]\n",
            "--2019-03-14 14:29:12--  https://imperialcollegelondon.box.com/public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n",
            "Reusing existing connection to imperialcollegelondon.box.com:443.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://imperialcollegelondon.app.box.com/public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip [following]\n",
            "--2019-03-14 14:29:12--  https://imperialcollegelondon.app.box.com/public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n",
            "Resolving imperialcollegelondon.app.box.com (imperialcollegelondon.app.box.com)... 103.116.4.199\n",
            "Connecting to imperialcollegelondon.app.box.com (imperialcollegelondon.app.box.com)|103.116.4.199|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://public.boxcloud.com/d/1/b1!uCRzKRn_WU4aRiaX3qvMB0QQYls_7vCak1nN79jVxbWkFTCxbvPxaW2suaa46561rTd2WzT0xh-ltxC5QFxlANTXb-OhfkjS0_eLUQJAJmsQLgLakVE1wqaTMithJd9p1A0kKM65IlOEeQTqktswk1DSctwROgjYeAA3WbFmQZrTiFFkZq9wzITDJPrW0QGigejKoB7oJR0WPBBVWfoD_SeOYMpn9DXMSK-nJCW_7jtOrKc49aZ5KKdIP6wHXxa3Q1f4iJOubRGFH8aw5PpvggQt2Nd9i3cTqEkiCJWL3PymGGIVjDjr7Xd2dT3LsWSogaQxiSvyiiSU9bHnuHxd6hrR__zg35DC7OutE4feHWP2gwBqnUnhIDQZj7Cef3OKg8Wi8XoalBxzWUxo1YZ_veVKM4g5NK_hi1yVN_7SDqffpnSgafyuKosQqxnG7yb5aE6pK60lqh4fXwDh9l-n1uu5YwNpl1ANWsnRQVBg1aUexnCVgD8NbpSZ0mVEpfnbtn6lJkgcw-r7fbwjiLgRTXF_e03lpTJItRXGVyLgJqOajqbhHw6EJYXIRWF2qx3LCDvxZBjPpVeVbMergrhEsz8e8hVU6r5LRJme9lTmrxCwPF2RenIO4Yb2bu6NQloZTpnZApetqqZ9CAzkcI_je1et2uQsW_cZ7iu8ynCCKWG0qGpYT5Ub-leGI5kCpH99yPOHoRJMOmwLlgMZObcaNavz0rhgtakPkJ4XVi2rWGVUkPjr-opiH2pN-cPUPcsa0rqMwm5Lztcj_PdDl4MMdmE04hPBI0l-BEp3lfLrpmISspa85TfZ-puuHjuT-QKo8RrD18ObVfLgjcIejH3OUJ9Ok1gJKQfCif0gdl8Tr_wdo9SD7UhPtGRE5sCEoBqUoc2ETMnD8gixfqis0m3oxZjsj5HHHH7j_okKi32NaIzGOpbnbYbRcs9NkxpQodqAZJ6CH0FoygsLS_8yK3-lxL0zFxYvIOEG9uT9smLYcJqTKaFsWW0-HKFMaRDW1BGcEcD6-gaGnfK6mItDecpd8h9VP72exX356f96vVANvEPyd43Eb4vfJe6NN1hZdqVcCqOegoXpmuC9f5sta1QfC5PRyr8q-pAThn8tYpIQxD8fwYixzE6EonTOEUZ6d1oMzMfO2G8udNf58W0NMYmt15ZQMT5Znjjb2jrh2tUKiMhjlM-UWO_62yajwNjyblzo55UIcD84qlsTMKOrnurFnl0hkb1onXI2Df4by3QNLQpltdTli47LHteuJfmsqP_Gz6WpCqDT1xJFIXrp_IzDR6zHU2SBEbDBGy_MuH6RTs4nAiLPZME4rZ6LgkDcA1D5HdlPYYsydsxV0VPsyv58-zJXh6FOgFH4GtS6m6IJnIExfOvdJH36MVwQUGogtLcEMcODFV6FEgJGxw7KWLzanvL-WzrwU04SgRJ6Dh7Hz7b9_XagZu2cW_olFWxhA8jrjAUReAS0y8r9N6fgPHYAmSwwr5mLTPV2Nb1c/download [following]\n",
            "--2019-03-14 14:29:13--  https://public.boxcloud.com/d/1/b1!uCRzKRn_WU4aRiaX3qvMB0QQYls_7vCak1nN79jVxbWkFTCxbvPxaW2suaa46561rTd2WzT0xh-ltxC5QFxlANTXb-OhfkjS0_eLUQJAJmsQLgLakVE1wqaTMithJd9p1A0kKM65IlOEeQTqktswk1DSctwROgjYeAA3WbFmQZrTiFFkZq9wzITDJPrW0QGigejKoB7oJR0WPBBVWfoD_SeOYMpn9DXMSK-nJCW_7jtOrKc49aZ5KKdIP6wHXxa3Q1f4iJOubRGFH8aw5PpvggQt2Nd9i3cTqEkiCJWL3PymGGIVjDjr7Xd2dT3LsWSogaQxiSvyiiSU9bHnuHxd6hrR__zg35DC7OutE4feHWP2gwBqnUnhIDQZj7Cef3OKg8Wi8XoalBxzWUxo1YZ_veVKM4g5NK_hi1yVN_7SDqffpnSgafyuKosQqxnG7yb5aE6pK60lqh4fXwDh9l-n1uu5YwNpl1ANWsnRQVBg1aUexnCVgD8NbpSZ0mVEpfnbtn6lJkgcw-r7fbwjiLgRTXF_e03lpTJItRXGVyLgJqOajqbhHw6EJYXIRWF2qx3LCDvxZBjPpVeVbMergrhEsz8e8hVU6r5LRJme9lTmrxCwPF2RenIO4Yb2bu6NQloZTpnZApetqqZ9CAzkcI_je1et2uQsW_cZ7iu8ynCCKWG0qGpYT5Ub-leGI5kCpH99yPOHoRJMOmwLlgMZObcaNavz0rhgtakPkJ4XVi2rWGVUkPjr-opiH2pN-cPUPcsa0rqMwm5Lztcj_PdDl4MMdmE04hPBI0l-BEp3lfLrpmISspa85TfZ-puuHjuT-QKo8RrD18ObVfLgjcIejH3OUJ9Ok1gJKQfCif0gdl8Tr_wdo9SD7UhPtGRE5sCEoBqUoc2ETMnD8gixfqis0m3oxZjsj5HHHH7j_okKi32NaIzGOpbnbYbRcs9NkxpQodqAZJ6CH0FoygsLS_8yK3-lxL0zFxYvIOEG9uT9smLYcJqTKaFsWW0-HKFMaRDW1BGcEcD6-gaGnfK6mItDecpd8h9VP72exX356f96vVANvEPyd43Eb4vfJe6NN1hZdqVcCqOegoXpmuC9f5sta1QfC5PRyr8q-pAThn8tYpIQxD8fwYixzE6EonTOEUZ6d1oMzMfO2G8udNf58W0NMYmt15ZQMT5Znjjb2jrh2tUKiMhjlM-UWO_62yajwNjyblzo55UIcD84qlsTMKOrnurFnl0hkb1onXI2Df4by3QNLQpltdTli47LHteuJfmsqP_Gz6WpCqDT1xJFIXrp_IzDR6zHU2SBEbDBGy_MuH6RTs4nAiLPZME4rZ6LgkDcA1D5HdlPYYsydsxV0VPsyv58-zJXh6FOgFH4GtS6m6IJnIExfOvdJH36MVwQUGogtLcEMcODFV6FEgJGxw7KWLzanvL-WzrwU04SgRJ6Dh7Hz7b9_XagZu2cW_olFWxhA8jrjAUReAS0y8r9N6fgPHYAmSwwr5mLTPV2Nb1c/download\n",
            "Resolving public.boxcloud.com (public.boxcloud.com)... 107.152.24.200, 107.152.25.200\n",
            "Connecting to public.boxcloud.com (public.boxcloud.com)|107.152.24.200|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4088106554 (3.8G) [application/zip]\n",
            "Saving to: ‘hpatches_data.zip’\n",
            "\n",
            "hpatches_data.zip   100%[===================>]   3.81G  18.6MB/s    in 3m 13s  \n",
            "\n",
            "2019-03-14 14:32:27 (20.2 MB/s) - ‘hpatches_data.zip’ saved [4088106554/4088106554]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "36mBTFvPCxY9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Extract data\n",
        "!unzip -q ./hpatches_data.zip\n",
        "!rm ./hpatches_data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kitxViHl-fBj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "d1a7ef32-bdba-4d77-bf55-c03cbea33d43"
      },
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline_code.ipynb  \u001b[0m\u001b[01;34mImages\u001b[0m/        README.md    temp_model.py   utils.pyc\n",
            "\u001b[01;34mhpatches\u001b[0m/            read_data.py   splits.json  temp_model.pyc\n",
            "\u001b[01;34mhpatches-benchmark\u001b[0m/  read_data.pyc  \u001b[01;34mtasks\u001b[0m/       utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9n_f7bEi-2C_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "772cc8f8-f3f1-4b9c-dcaa-befc8b20ed13"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/drive'\n",
            "/root\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Rjyr96hR_4wS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Importing Necessary Modules\n",
        "\n",
        "We now import the modules we will use in this baseline code. "
      ]
    },
    {
      "metadata": {
        "id": "o0KYfe-at9KN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "74408ec6-4034-408b-934d-b2c59f1cdc84"
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import json\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda, Reshape\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, ReLU, Conv2DTranspose\n",
        "from keras.layers import Input, UpSampling2D, concatenate  \n",
        "\n",
        "from read_data import HPatches, DataGeneratorDesc, hpatches_sequence_folder, DenoiseHPatches, tps\n",
        "from utils import generate_desc_csv, plot_denoise, plot_triplet"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "AFG0LyAct_-l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The `read_data` and `utils` imports are functions provided in the repository we just cloned. You can navigate through the *File tab* and check what those functions do for a better understanding.\n",
        "\n",
        "![texto del enlace](https://i.ibb.co/HnfSvfT/filetab.png)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "tnSW3zLPmsbt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1129
        },
        "outputId": "7e68ec24-2c23-4921-c87a-e11501996546"
      },
      "cell_type": "code",
      "source": [
        "! pip install hyperas"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting hyperas\n",
            "  Downloading https://files.pythonhosted.org/packages/c5/f2/6f3014fea05b0011ab58216d3ae6c82ddf73359179aa7c764cabf3088576/hyperas-0.4.1-py2-none-any.whl\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python2.7/dist-packages (from hyperas) (0.1.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python2.7/dist-packages (from hyperas) (2.2.4)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python2.7/dist-packages (from hyperas) (5.4.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python2.7/dist-packages (from hyperas) (4.4.0)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python2.7/dist-packages (from hyperas) (1.0.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python2.7/dist-packages (from hyperas) (0.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (from hyperopt->hyperas) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (from hyperopt->hyperas) (1.14.6)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python2.7/dist-packages (from hyperopt->hyperas) (3.7.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python2.7/dist-packages (from hyperopt->hyperas) (2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python2.7/dist-packages (from hyperopt->hyperas) (4.28.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python2.7/dist-packages (from hyperopt->hyperas) (0.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python2.7/dist-packages (from hyperopt->hyperas) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python2.7/dist-packages (from keras->hyperas) (1.0.7)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python2.7/dist-packages (from keras->hyperas) (1.0.9)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python2.7/dist-packages (from keras->hyperas) (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python2.7/dist-packages (from keras->hyperas) (3.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python2.7/dist-packages (from nbconvert->hyperas) (2.10)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python2.7/dist-packages (from nbconvert->hyperas) (0.5.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python2.7/dist-packages (from nbconvert->hyperas) (0.4.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python2.7/dist-packages (from nbconvert->hyperas) (3.1.0)\n",
            "Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python2.7/dist-packages (from nbconvert->hyperas) (0.8.4)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python2.7/dist-packages (from nbconvert->hyperas) (4.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python2.7/dist-packages (from nbconvert->hyperas) (2.1.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from nbconvert->hyperas) (1.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python2.7/dist-packages (from nbconvert->hyperas) (4.3.2)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python2.7/dist-packages (from nbformat->hyperas) (2.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python2.7/dist-packages (from nbformat->hyperas) (0.2.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python2.7/dist-packages (from jupyter->hyperas) (7.4.2)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python2.7/dist-packages (from jupyter->hyperas) (4.4.3)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python2.7/dist-packages (from jupyter->hyperas) (5.2.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python2.7/dist-packages (from jupyter->hyperas) (4.6.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python2.7/dist-packages (from jupyter->hyperas) (5.2.2)\n",
            "Requirement already satisfied: configparser>=3.5; python_version == \"2.7\" in /usr/local/lib/python2.7/dist-packages (from entrypoints->hyperas) (3.7.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python2.7/dist-packages (from networkx->hyperopt->hyperas) (4.3.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python2.7/dist-packages (from jinja2->nbconvert->hyperas) (1.1.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python2.7/dist-packages (from bleach->nbconvert->hyperas) (0.5.1)\n",
            "Requirement already satisfied: enum34; python_version == \"2.7\" in /usr/local/lib/python2.7/dist-packages (from traitlets>=4.2->nbconvert->hyperas) (1.1.6)\n",
            "Requirement already satisfied: functools32; python_version == \"2.7\" in /usr/local/lib/python2.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat->hyperas) (3.2.3.post2)\n",
            "Requirement already satisfied: ipython<6.0.0,>=4.0.0; python_version < \"3.3\" in /usr/local/lib/python2.7/dist-packages (from ipywidgets->jupyter->hyperas) (5.5.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.4.0 in /usr/local/lib/python2.7/dist-packages (from ipywidgets->jupyter->hyperas) (3.4.2)\n",
            "Requirement already satisfied: jupyter-client>=4.1 in /usr/local/lib/python2.7/dist-packages (from qtconsole->jupyter->hyperas) (5.2.4)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python2.7/dist-packages (from jupyter-console->jupyter->hyperas) (1.0.15)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python2.7/dist-packages (from ipykernel->jupyter->hyperas) (4.5.3)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python2.7/dist-packages (from notebook->jupyter->hyperas) (0.8.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python2.7/dist-packages (from ipython<6.0.0,>=4.0.0; python_version < \"3.3\"->ipywidgets->jupyter->hyperas) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python2.7/dist-packages (from ipython<6.0.0,>=4.0.0; python_version < \"3.3\"->ipywidgets->jupyter->hyperas) (0.7.5)\n",
            "Requirement already satisfied: backports.shutil-get-terminal-size; python_version == \"2.7\" in /usr/local/lib/python2.7/dist-packages (from ipython<6.0.0,>=4.0.0; python_version < \"3.3\"->ipywidgets->jupyter->hyperas) (1.0.0)\n",
            "Requirement already satisfied: pathlib2; python_version == \"2.7\" or python_version == \"3.3\" in /usr/local/lib/python2.7/dist-packages (from ipython<6.0.0,>=4.0.0; python_version < \"3.3\"->ipywidgets->jupyter->hyperas) (2.3.3)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python2.7/dist-packages (from ipython<6.0.0,>=4.0.0; python_version < \"3.3\"->ipywidgets->jupyter->hyperas) (4.6.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python2.7/dist-packages (from ipython<6.0.0,>=4.0.0; python_version < \"3.3\"->ipywidgets->jupyter->hyperas) (40.8.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python2.7/dist-packages (from jupyter-client>=4.1->qtconsole->jupyter->hyperas) (17.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python2.7/dist-packages (from jupyter-client>=4.1->qtconsole->jupyter->hyperas) (2.5.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python2.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->hyperas) (0.1.7)\n",
            "Requirement already satisfied: singledispatch in /usr/local/lib/python2.7/dist-packages (from tornado>=4.0->ipykernel->jupyter->hyperas) (3.4.0.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python2.7/dist-packages (from tornado>=4.0->ipykernel->jupyter->hyperas) (2018.11.29)\n",
            "Requirement already satisfied: backports_abc>=0.4 in /usr/local/lib/python2.7/dist-packages (from tornado>=4.0->ipykernel->jupyter->hyperas) (0.5)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python2.7/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->jupyter->hyperas) (0.6.0)\n",
            "Requirement already satisfied: scandir; python_version < \"3.5\" in /usr/local/lib/python2.7/dist-packages (from pathlib2; python_version == \"2.7\" or python_version == \"3.3\"->ipython<6.0.0,>=4.0.0; python_version < \"3.3\"->ipywidgets->jupyter->hyperas) (1.9.0)\n",
            "Installing collected packages: hyperas\n",
            "Successfully installed hyperas-0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2Y61ZKWZ7o5k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We also fix the seeds of the pseudo-random number generators to have reproducible results. The idea of fixing the seed is having the same results every time the algorithm is run if there are no changes in the code."
      ]
    },
    {
      "metadata": {
        "id": "NXL31ez-AT5h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "random.seed(1234)\n",
        "np.random.seed(1234)\n",
        "tf.set_random_seed(1234)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_OqFkNujBGzf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we load the data. The original HPatches dataset has several splits, which are used to separate the available sequences in train sequences and test sequences. For our experiments in N-HPatches we use the same splits as in HPatches. Specifically, we load (and report results) using the split `'a'`:\n"
      ]
    },
    {
      "metadata": {
        "id": "ABKDHB9RApZk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hpatches_dir = './hpatches'\n",
        "splits_path = './splits.json'\n",
        "\n",
        "splits_json = json.load(open(splits_path, 'rb'))\n",
        "split = splits_json['a']\n",
        "\n",
        "train_fnames = split['train']\n",
        "test_fnames = split['test']\n",
        "\n",
        "seqs = glob.glob(hpatches_dir+'/*')\n",
        "seqs = [os.path.abspath(p) for p in seqs]   \n",
        "seqs_train = list(filter(lambda x: x.split('/')[-1] in train_fnames, seqs)) \n",
        "seqs_test = list(filter(lambda x: x.split('/')[-1] in split['test'], seqs)) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qeWik0vMEtuC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Models and loss"
      ]
    },
    {
      "metadata": {
        "id": "LYJz8BDzBkIx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We now define three functions that define the main modules of our baseline. \n",
        "\n",
        "*   **get_denoise_model(..)** returns the denoising model. The input for the function is the size of the patch, which will be *1x32x32*, and it outputs a keras denoising model. \n",
        "*   **get_descriptor_model(..)** builts the descriptor model. The input for the function is the size of the patch, which will be *1x32x32*, and it outputs a keras descriptor model. The model we use as baseline returns a descriptor of dimension *128x1*.\n",
        "*   **triplet_loss(..)** defines the loss function which is used to train the descriptor model. \n",
        "\n",
        "You can modify the models in these functions and run the training code again. For example, the given denoising model is quite shallow, maybe using a deeper network can improve results. Or testing new initializations for the weights. Or maybe adding dropout. Or modifying the loss function somehow..."
      ]
    },
    {
      "metadata": {
        "id": "W6QbkHnbuIUD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def data():\n",
        "  denoise_generator = DenoiseHPatches(random.sample(seqs_train, 3), batch_size=50)\n",
        "  denoise_generator_val = DenoiseHPatches(random.sample(seqs_test, 1), batch_size=50)\n",
        "  \n",
        "  return denoise_generator,denoise_generator_val\n",
        "\n",
        "def get_denoise_model(shape):\n",
        "    \n",
        "  inputs = Input(shape)\n",
        "  \n",
        "  ## Encoder starts\n",
        "  conv1 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "  \n",
        "  ## Bottleneck\n",
        "  conv2 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "\n",
        "  ## Now the decoder starts\n",
        "  up3 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv2))\n",
        "  merge3 = concatenate([conv1,up3], axis = -1)\n",
        "  conv3 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge3)\n",
        "    \n",
        "  conv4 = Conv2D(1, 3,  padding = 'same')(conv3)\n",
        "\n",
        "  shallow_net = Model(inputs = inputs, outputs = conv4)\n",
        "  \n",
        "  \n",
        "  return shallow_net\n",
        "\n",
        "def get_unet(shape, activation=ReLU):\n",
        "  \n",
        "    inputs = Input(shape)\n",
        "    conv1 = Dropout(0)(activation()(Conv2D(32, (3, 3), padding='same',kernel_initializer = 'he_normal')(inputs)))\n",
        "    #conv1 = Dropout(do)(activation()(Conv2D(32, (3, 3), padding='same',kernel_initializer = 'he_normal')(conv1)))\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Dropout({{uniform(0, 1)}})(activation()(Conv2D(64, (3, 3), padding='same',kernel_initializer = 'he_normal')(pool1)))\n",
        "    #conv2 = Dropout(do)(activation()(Conv2D(64, (3, 3), padding='same',kernel_initializer = 'he_normal')(conv2)))\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Dropout({{uniform(0, 1)}})(activation()(Conv2D(128, (3, 3), padding='same',kernel_initializer = 'he_normal')(pool2)))\n",
        "    #conv3 = Dropout(do)(activation()(Conv2D(128, (3, 3), padding='same',kernel_initializer = 'he_normal')(conv3)))\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Dropout(0)(activation()(Conv2D(256, (3, 3), padding='same',kernel_initializer = 'he_normal')(pool3)))\n",
        "    #conv4 = Dropout(do)(activation()(Conv2D(256, (3, 3), padding='same',kernel_initializer = 'he_normal')(conv4)))\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    conv5 = Dropout({{uniform(0, 1)}})(activation()(Conv2D(512, (3, 3), padding='same',kernel_initializer = 'he_normal')(pool4)))\n",
        "    #conv5 = Dropout(do)(activation()(Conv2D(512, (3, 3), padding='same',kernel_initializer = 'he_normal')(conv5)))\n",
        "\n",
        "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same',kernel_initializer = 'he_normal')(conv5), conv4], axis=3)\n",
        "    conv6 = Dropout(0)(activation()(Conv2D(256, (3, 3), padding='same',kernel_initializer = 'he_normal')(up6)))\n",
        "    #conv6 = Dropout(do)(activation()(Conv2D(256, (3, 3), padding='same',kernel_initializer = 'he_normal')(conv6)))\n",
        "\n",
        "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same',kernel_initializer = 'he_normal')(conv6), conv3], axis=3)\n",
        "    conv7 = Dropout({{uniform(0, 1)}})(activation()(Conv2D(128, (3, 3), padding='same',kernel_initializer = 'he_normal')(up7)))\n",
        "    #conv7 = Dropout(do)(activation()(Conv2D(128, (3, 3), padding='same',kernel_initializer = 'he_normal')(conv7)))\n",
        "\n",
        "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same',kernel_initializer = 'he_normal')(conv7), conv2], axis=3)\n",
        "    conv8 = Dropout({{uniform(0, 1)}})(activation()(Conv2D(64, (3, 3), padding='same',kernel_initializer = 'he_normal')(up8)))\n",
        "    #conv8 = Dropout(do)(activation()(Conv2D(64, (3, 3), padding='same',kernel_initializer = 'he_normal')(conv8)))\n",
        "\n",
        "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same',kernel_initializer = 'he_normal')(conv8), conv1], axis=3)\n",
        "    conv9 = Dropout(0)(activation()(Conv2D(32, (3, 3), padding='same',kernel_initializer = 'he_normal')(up9)))\n",
        "    #conv9 = Dropout(do)(activation()(Conv2D(32, (3, 3), padding='same',kernel_initializer = 'he_normal')(conv9)))\n",
        "\n",
        "    conv10 = Dropout(0)(Conv2D(1, (1, 1), activation='relu',padding='same')(conv9))\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[conv10])\n",
        "   \n",
        "    #denoise_generator = DenoiseHPatches(random.sample(seqs_train, 3), batch_size=50)\n",
        "    #denoise_generator_val = DenoiseHPatches(random.sample(seqs_test, 1), batch_size=50)    \n",
        "    \n",
        "    denoise_model = model\n",
        "    \n",
        "    \n",
        "    sgd = keras.optimizers.SGD(lr=0.00001, momentum=0.9, nesterov=True)\n",
        "    denoise_model.compile(loss='mean_absolute_error', optimizer=sgd, metrics=['mae'])\n",
        "### Use a loop to save for each epoch the weights in an external website in\n",
        "### case colab stops. Every time you call fit/fit_generator the weigths are NOT\n",
        "### reset, so e.g. calling 5 times fit(epochs=1) behave as fit(epochs=5)\n",
        "\n",
        "    denoise_history = denoise_model.fit_generator(generator=denoise_generator, \n",
        "                                                epochs=10, verbose=1, \n",
        "                                                validation_data=denoise_generator_val,\n",
        "                                                )\n",
        "    \n",
        "    validation_acc = np.amax(denoise_history.history['val_loss']) \n",
        "    print('Best validation loss of epoch:', validation_acc)\n",
        "    return {'loss': validation_acc, 'status': STATUS_OK, 'model': model},denoise_history\n",
        "\n",
        "\n",
        "\n",
        "def get_descriptor_model(shape):\n",
        "  \n",
        "  '''Architecture copies HardNet architecture'''\n",
        "  \n",
        "  init_weights = keras.initializers.he_normal()\n",
        "  \n",
        "  descriptor_model = Sequential()\n",
        "  descriptor_model.add(Conv2D(32, 3, padding='same', input_shape=shape, use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(32, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(64, 3, padding='same', strides=2, use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(64, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(128, 3, padding='same', strides=2,  use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(128, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "  descriptor_model.add(Dropout(0.3))\n",
        "\n",
        "  descriptor_model.add(Conv2D(128, 8, padding='valid', use_bias = True, kernel_initializer=init_weights))\n",
        "  \n",
        "  # Final descriptor reshape\n",
        "  descriptor_model.add(Reshape((128,)))\n",
        "  \n",
        "  return descriptor_model\n",
        "  \n",
        "  \n",
        "def triplet_loss(x):\n",
        "  \n",
        "  output_dim = 128\n",
        "  a, p, n = x\n",
        "  _alpha = 1.0\n",
        "  positive_distance = K.mean(K.square(a - p), axis=-1)\n",
        "  negative_distance = K.mean(K.square(a - n), axis=-1)\n",
        "  \n",
        "  return K.expand_dims(K.maximum(0.0, positive_distance - negative_distance + _alpha), axis = 1)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "\n",
        "def plot_history(history, metric = None):\n",
        "  # Plots the loss history of training and validation (if existing)\n",
        "  # and a given metric\n",
        "  \n",
        "  if metric != None:\n",
        "    fig, axes = plt.subplots(2,1)\n",
        "    axes[0].plot(history.history[metric])\n",
        "    try:\n",
        "      axes[0].plot(history.history['val_'+metric])\n",
        "      axes[0].legend(['Train', 'Val'])\n",
        "    except:\n",
        "      pass\n",
        "    axes[0].set_title('{:s}'.format(metric))\n",
        "    axes[0].set_ylabel('{:s}'.format(metric))\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    fig.subplots_adjust(hspace=0.5)\n",
        "    axes[1].plot(history.history['loss'])\n",
        "    try:\n",
        "      axes[1].plot(history.history['val_loss'])\n",
        "      axes[1].legend(['Train', 'Val'])\n",
        "    except:\n",
        "      pass\n",
        "    axes[1].set_title('Model Loss')\n",
        "    axes[1].set_ylabel('Loss')\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "  else:\n",
        "    plt.plot(history.history['loss'])\n",
        "    try:\n",
        "      plt.plot(history.history['val_loss'])\n",
        "      plt.legend(['Train', 'Val'])\n",
        "    except:\n",
        "      pass\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "murBXgSM6qNn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "98761421-bc9e-48e2-d818-5bc5b3c3f833"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QhjH-bEv8UpZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "eafd03ad-ade2-470a-8020-8c5199ecb859"
      },
      "cell_type": "code",
      "source": [
        "%cd drive\n",
        "%ls"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'drive'\n",
            "/root\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3MkGWfiyze_W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4414
        },
        "outputId": "43c69c09-9af6-4965-c01c-5adcc1714464"
      },
      "cell_type": "code",
      "source": [
        "shape=(32,32,1)\n",
        "best_run, best_model = optim.minimize(model=get_unet,\n",
        "                                          data=data,\n",
        "                                          algo=tpe.suggest,\n",
        "                                          max_evals=5,\n",
        "                                          trials=Trials(),\n",
        "                                          notebook_name = '\n",
        "                                         \n",
        "                                          )\n",
        "\n",
        "denoise_generator, denoise_generator_val = data()\n",
        "\n",
        "print(\"Evalutation of best performing model:\")\n",
        "print(best_model.evaluate(X_test, Y_test))\n",
        "print(\"Best performing model chosen hyper-parameters:\")\n",
        "print(best_run)\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> Imports:\n",
            "#coding=utf-8\n",
            "\n",
            "try:\n",
            "    import psutil\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import humanize\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import os\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import GPUtil as GPU\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import sys\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import json\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import os\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import glob\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import time\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import tensorflow as tf\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import numpy as np\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import cv2\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import random\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import keras\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras import backend as K\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.models import Sequential, Model\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda, Reshape\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers import Input, UpSampling2D, concatenate\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from read_data import HPatches, DataGeneratorDesc, hpatches_sequence_folder, DenoiseHPatches, tps\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from utils import generate_desc_csv, plot_denoise, plot_triplet\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from google.colab import files\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers import Lambda\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from google.colab import auth\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from googleapiclient.http import MediaFileUpload\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from googleapiclient.discovery import build\n",
            "except:\n",
            "    pass\n",
            "\n",
            ">>> Hyperas search space:\n",
            "\n",
            "def get_space():\n",
            "    return {\n",
            "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
            "        'Dropout_1': hp.uniform('Dropout_1', 0, 1),\n",
            "        'Dropout_2': hp.uniform('Dropout_2', 0, 1),\n",
            "        'Dropout_3': hp.uniform('Dropout_3', 0, 1),\n",
            "        'Dropout_4': hp.uniform('Dropout_4', 0, 1),\n",
            "    }\n",
            "\n",
            ">>> Data\n",
            "  1: \n",
            "  2: denoise_generator = DenoiseHPatches(random.sample(seqs_train, 3), batch_size=50)\n",
            "  3: denoise_generator_val = DenoiseHPatches(random.sample(seqs_test, 1), batch_size=50)\n",
            "  4: \n",
            "  5: \n",
            "  6: \n",
            "  7: \n",
            ">>> Resulting replaced keras model:\n",
            "\n",
            "   1: def keras_fmin_fnct(space):\n",
            "   2: \n",
            "   3:   \n",
            "   4:     inputs = Input(shape)\n",
            "   5:     conv1 = Dropout(0)(activation()(Conv2D(32, (3, 3), padding='same',kernel_initializer = 'he_normal')(inputs)))\n",
            "   6:     #conv1 = Dropout(do)(activation()(Conv2D(32, (3, 3), padding='same',kernel_initializer = 'he_normal')(conv1)))\n",
            "   7:     pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
            "   8: \n",
            "   9:     conv2 = Dropout(space['Dropout'])(activation()(Conv2D(64, (3, 3), padding='same',kernel_initializer = 'he_normal')(pool1)))\n",
            "  10:     #conv2 = Dropout(do)(activation()(Conv2D(64, (3, 3), padding='same',kernel_initializer = 'he_normal')(conv2)))\n",
            "  11:     pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
            "  12: \n",
            "  13:     conv3 = Dropout(space['Dropout_1'])(activation()(Conv2D(128, (3, 3), padding='same',kernel_initializer = 'he_normal')(pool2)))\n",
            "  14:     #conv3 = Dropout(do)(activation()(Conv2D(128, (3, 3), padding='same',kernel_initializer = 'he_normal')(conv3)))\n",
            "  15:     pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
            "  16: \n",
            "  17:     conv4 = Dropout(0)(activation()(Conv2D(256, (3, 3), padding='same',kernel_initializer = 'he_normal')(pool3)))\n",
            "  18:     #conv4 = Dropout(do)(activation()(Conv2D(256, (3, 3), padding='same',kernel_initializer = 'he_normal')(conv4)))\n",
            "  19:     pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
            "  20: \n",
            "  21:     conv5 = Dropout(space['Dropout_2'])(activation()(Conv2D(512, (3, 3), padding='same',kernel_initializer = 'he_normal')(pool4)))\n",
            "  22:     #conv5 = Dropout(do)(activation()(Conv2D(512, (3, 3), padding='same',kernel_initializer = 'he_normal')(conv5)))\n",
            "  23: \n",
            "  24:     up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same',kernel_initializer = 'he_normal')(conv5), conv4], axis=3)\n",
            "  25:     conv6 = Dropout(0)(activation()(Conv2D(256, (3, 3), padding='same',kernel_initializer = 'he_normal')(up6)))\n",
            "  26:     #conv6 = Dropout(do)(activation()(Conv2D(256, (3, 3), padding='same',kernel_initializer = 'he_normal')(conv6)))\n",
            "  27: \n",
            "  28:     up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same',kernel_initializer = 'he_normal')(conv6), conv3], axis=3)\n",
            "  29:     conv7 = Dropout(space['Dropout_3'])(activation()(Conv2D(128, (3, 3), padding='same',kernel_initializer = 'he_normal')(up7)))\n",
            "  30:     #conv7 = Dropout(do)(activation()(Conv2D(128, (3, 3), padding='same',kernel_initializer = 'he_normal')(conv7)))\n",
            "  31: \n",
            "  32:     up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same',kernel_initializer = 'he_normal')(conv7), conv2], axis=3)\n",
            "  33:     conv8 = Dropout(space['Dropout_4'])(activation()(Conv2D(64, (3, 3), padding='same',kernel_initializer = 'he_normal')(up8)))\n",
            "  34:     #conv8 = Dropout(do)(activation()(Conv2D(64, (3, 3), padding='same',kernel_initializer = 'he_normal')(conv8)))\n",
            "  35: \n",
            "  36:     up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same',kernel_initializer = 'he_normal')(conv8), conv1], axis=3)\n",
            "  37:     conv9 = Dropout(0)(activation()(Conv2D(32, (3, 3), padding='same',kernel_initializer = 'he_normal')(up9)))\n",
            "  38:     #conv9 = Dropout(do)(activation()(Conv2D(32, (3, 3), padding='same',kernel_initializer = 'he_normal')(conv9)))\n",
            "  39: \n",
            "  40:     conv10 = Dropout(0)(Conv2D(1, (1, 1), activation='relu',padding='same')(conv9))\n",
            "  41: \n",
            "  42:     model = Model(inputs=[inputs], outputs=[conv10])\n",
            "  43:    \n",
            "  44:     #denoise_generator = DenoiseHPatches(random.sample(seqs_train, 3), batch_size=50)\n",
            "  45:     #denoise_generator_val = DenoiseHPatches(random.sample(seqs_test, 1), batch_size=50)    \n",
            "  46:     \n",
            "  47:     denoise_model = model\n",
            "  48:     \n",
            "  49:     \n",
            "  50:     sgd = keras.optimizers.SGD(lr=0.00001, momentum=0.9, nesterov=True)\n",
            "  51:     denoise_model.compile(loss='mean_absolute_error', optimizer=sgd, metrics=['mae'])\n",
            "  52: ### Use a loop to save for each epoch the weights in an external website in\n",
            "  53: ### case colab stops. Every time you call fit/fit_generator the weigths are NOT\n",
            "  54: ### reset, so e.g. calling 5 times fit(epochs=1) behave as fit(epochs=5)\n",
            "  55: \n",
            "  56:     denoise_history = denoise_model.fit_generator(generator=denoise_generator, \n",
            "  57:                                                 epochs=10, verbose=1, \n",
            "  58:                                                 validation_data=denoise_generator_val,\n",
            "  59:                                                 )\n",
            "  60:     \n",
            "  61:     validation_acc = np.amax(denoise_history.history['val_loss']) \n",
            "  62:     print('Best validation loss of epoch:', validation_acc)\n",
            "  63:     return {'loss': validation_acc, 'status': STATUS_OK, 'model': model},denoise_history\n",
            "  64: \n",
            "Unexpected error: <type 'exceptions.NameError'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-2021801f6d58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                                           \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                           \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                           \u001b[0mnotebook_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Baseline_code'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                           )\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/hyperas/optim.pyc\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(model, data, algo, max_evals, trials, functions, rseed, notebook_name, verbose, eval_space, return_space, keep_temp)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                      \u001b[0mnotebook_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnotebook_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                                      \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                                      keep_temp=keep_temp)\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/hyperas/optim.pyc\u001b[0m in \u001b[0;36mbase_minimizer\u001b[0;34m(model, data, functions, algo, max_evals, trials, rseed, full_model_string, notebook_name, verbose, stack, keep_temp)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mtemp_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_fmin_fnct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unexpected error: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/keras_triplet_descriptor/temp_model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhyperopt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTATUS_OK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m \u001b[0mdenoise_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDenoiseHPatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0mdenoise_generator_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDenoiseHPatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'seqs_train' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "RlS5zcV7EJgp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Denoising Image Patches\n"
      ]
    },
    {
      "metadata": {
        "id": "wHxHwjUd3-pY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We use the *DenoiseHPatches* class implemented in the read_data.py file, which takes as input the list of sequences to load and the size of batches. \n",
        "\n",
        "*DenoiseHPatches* outputs batches where the input data is the noisy image and the label is the clean image, so we can use a mean absolute error (MSE) metric as loss function. You can try to use different metrics here to see if that improves results. \n",
        "\n",
        "Afterward, we take a subset of training and validation sequences by using *random.sample* (3 sequences for training and 1 for validation data). The purpose of doing so is just to speed-up training when trying different setups, but you should use the whole dataset when training your final model. Remove the random.sample function to give the generator all the training data.\n",
        "\n",
        "In addition, note that we are using the test set as validation. We will provide you with a new test set that will be used to evaluate your final model, and from which you will not have the clean images. \n",
        "\n",
        "**Updated**: Training should be quite faster now (1 epoch around 15 minutes)."
      ]
    },
    {
      "metadata": {
        "id": "m_VPSHmSK0dS",
        "colab_type": "code",
        "outputId": "2b10789e-7cf4-4538-c135-60514e9872b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "denoise_generator = DenoiseHPatches(random.sample(seqs_train, 3), batch_size=50)\n",
        "denoise_generator_val = DenoiseHPatches(random.sample(seqs_test, 1), batch_size=50)\n",
        "\n",
        "# Uncomment following lines for using all the data to train the denoising model\n",
        "# denoise_generator = DenoiseHPatches(seqs_train, batch_size=50)\n",
        "# denoise_generator_val = DenoiseHPatches(seqs_test, batch_size=50)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "-eUSba93Dttj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1381
        },
        "outputId": "84af36d8-1d5b-4cdc-811b-3c5575b1436a"
      },
      "cell_type": "code",
      "source": [
        "shape = (32, 32, 1)\n",
        "blah = get_unet(shape)\n",
        "\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:03<00:00,  1.25s/it]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1737/1737 [==============================] - 87s 50ms/step - loss: 8.8575 - mean_absolute_error: 8.8575 - val_loss: 7.4273 - val_mean_absolute_error: 7.4273\n",
            "Epoch 2/10\n",
            "1737/1737 [==============================] - 86s 49ms/step - loss: 7.1164 - mean_absolute_error: 7.1164 - val_loss: 7.3299 - val_mean_absolute_error: 7.3299\n",
            "Epoch 3/10\n",
            "1737/1737 [==============================] - 86s 49ms/step - loss: 6.9646 - mean_absolute_error: 6.9646 - val_loss: 7.2790 - val_mean_absolute_error: 7.2790\n",
            "Epoch 4/10\n",
            "1067/1737 [=================>............] - ETA: 29s - loss: 6.8710 - mean_absolute_error: 6.8710"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-eebc1035fd25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mblah\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_unet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-4421d289ac25>\u001b[0m in \u001b[0;36mget_unet\u001b[0;34m(shape, do, activation)\u001b[0m\n\u001b[1;32m     78\u001b[0m     denoise_history = denoise_model.fit_generator(generator=denoise_generator, \n\u001b[1;32m     79\u001b[0m                                                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                                                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdenoise_generator_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                                                 )\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training_generator.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "LcUkXZ4QN_6X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8u-1rFIUNomj",
        "colab_type": "code",
        "outputId": "0113ba95-64e3-435e-ab8b-b42ec37ab49e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = './log'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://e7164ff9.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SCymkcDdAAzp",
        "colab_type": "code",
        "outputId": "63afe100-6616-4790-e555-4c26ae699d3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = './log1'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://e7164ff9.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oC2RoQ0DOMnd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import TensorBoard\n",
        "tbCallBack = TensorBoard(log_dir='./log',\n",
        "                         write_graph=True,\n",
        "                         write_grads=True,\n",
        "                         write_images=True)\n",
        "\n",
        "tbCallBack1 = TensorBoard(log_dir='./log1',\n",
        "                         write_graph=True,\n",
        "                         write_grads=True,\n",
        "                         write_images=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H3wkjkpk4bRh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We set number of epochs to 1, tweak it, along with other hyperparameters, to improve the performance of the model."
      ]
    },
    {
      "metadata": {
        "id": "aPcyLkUytqfa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "checker = get_unet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "edwbgE6yKqcD",
        "colab_type": "code",
        "outputId": "911be4b5-d711-40f0-e30a-3317b88dd9e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3790
        }
      },
      "cell_type": "code",
      "source": [
        "sgd = keras.optimizers.SGD(lr=0.00001, momentum=0.9, nesterov=True)\n",
        "denoise_model.compile(loss='mean_absolute_error', optimizer=sgd, metrics=['mae'])\n",
        "epochs = 5\n",
        "denoise_model.summary()\n",
        "### Use a loop to save for each epoch the weights in an external website in\n",
        "### case colab stops. Every time you call fit/fit_generator the weigths are NOT\n",
        "### reset, so e.g. calling 5 times fit(epochs=1) behave as fit(epochs=5)\n",
        "\n",
        "denoise_history = denoise_model.fit_generator(generator=denoise_generator, \n",
        "                                                epochs=10, verbose=1, \n",
        "                                                validation_data=denoise_generator_val,\n",
        "                                                )\n",
        "  ### Saves optimizer and weights\n",
        "denoise_model.save('denoise.h5') \n",
        "  ### Uploads files to external hosting\n",
        "!curl -F \"file=@denoise.h5\" https://file.io\n",
        "plot_history(denoise_history)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_11 (InputLayer)           (None, 32, 32, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 32, 32, 32)   320         input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_66 (ReLU)                 (None, 32, 32, 32)   0           conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_71 (Dropout)            (None, 32, 32, 32)   0           re_lu_66[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 32, 32, 32)   9248        dropout_71[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_67 (ReLU)                 (None, 32, 32, 32)   0           conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_72 (Dropout)            (None, 32, 32, 32)   0           re_lu_67[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_24 (MaxPooling2D) (None, 16, 16, 32)   0           dropout_72[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 16, 16, 64)   18496       max_pooling2d_24[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_68 (ReLU)                 (None, 16, 16, 64)   0           conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_73 (Dropout)            (None, 16, 16, 64)   0           re_lu_68[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 16, 16, 64)   36928       dropout_73[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_69 (ReLU)                 (None, 16, 16, 64)   0           conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_74 (Dropout)            (None, 16, 16, 64)   0           re_lu_69[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_25 (MaxPooling2D) (None, 8, 8, 64)     0           dropout_74[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 8, 8, 128)    73856       max_pooling2d_25[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_70 (ReLU)                 (None, 8, 8, 128)    0           conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_75 (Dropout)            (None, 8, 8, 128)    0           re_lu_70[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 8, 8, 128)    147584      dropout_75[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_71 (ReLU)                 (None, 8, 8, 128)    0           conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_76 (Dropout)            (None, 8, 8, 128)    0           re_lu_71[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_26 (MaxPooling2D) (None, 4, 4, 128)    0           dropout_76[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 4, 4, 256)    295168      max_pooling2d_26[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_72 (ReLU)                 (None, 4, 4, 256)    0           conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_77 (Dropout)            (None, 4, 4, 256)    0           re_lu_72[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 4, 4, 256)    590080      dropout_77[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_73 (ReLU)                 (None, 4, 4, 256)    0           conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_78 (Dropout)            (None, 4, 4, 256)    0           re_lu_73[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_27 (MaxPooling2D) (None, 2, 2, 256)    0           dropout_78[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 2, 2, 512)    1180160     max_pooling2d_27[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_74 (ReLU)                 (None, 2, 2, 512)    0           conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_79 (Dropout)            (None, 2, 2, 512)    0           re_lu_74[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 2, 2, 512)    2359808     dropout_79[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_75 (ReLU)                 (None, 2, 2, 512)    0           conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_80 (Dropout)            (None, 2, 2, 512)    0           re_lu_75[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_17 (Conv2DTran (None, 4, 4, 256)    524544      dropout_80[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 4, 4, 512)    0           conv2d_transpose_17[0][0]        \n",
            "                                                                 dropout_78[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 4, 4, 256)    1179904     concatenate_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_76 (ReLU)                 (None, 4, 4, 256)    0           conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_81 (Dropout)            (None, 4, 4, 256)    0           re_lu_76[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 4, 4, 256)    590080      dropout_81[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_77 (ReLU)                 (None, 4, 4, 256)    0           conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_82 (Dropout)            (None, 4, 4, 256)    0           re_lu_77[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_18 (Conv2DTran (None, 8, 8, 128)    131200      dropout_82[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 8, 8, 256)    0           conv2d_transpose_18[0][0]        \n",
            "                                                                 dropout_76[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 8, 8, 128)    295040      concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_78 (ReLU)                 (None, 8, 8, 128)    0           conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_83 (Dropout)            (None, 8, 8, 128)    0           re_lu_78[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 8, 8, 128)    147584      dropout_83[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_79 (ReLU)                 (None, 8, 8, 128)    0           conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_84 (Dropout)            (None, 8, 8, 128)    0           re_lu_79[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_19 (Conv2DTran (None, 16, 16, 64)   32832       dropout_84[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 16, 16, 128)  0           conv2d_transpose_19[0][0]        \n",
            "                                                                 dropout_74[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 16, 16, 64)   73792       concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_80 (ReLU)                 (None, 16, 16, 64)   0           conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_85 (Dropout)            (None, 16, 16, 64)   0           re_lu_80[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 16, 16, 64)   36928       dropout_85[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_81 (ReLU)                 (None, 16, 16, 64)   0           conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_86 (Dropout)            (None, 16, 16, 64)   0           re_lu_81[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_20 (Conv2DTran (None, 32, 32, 32)   8224        dropout_86[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 32, 32, 64)   0           conv2d_transpose_20[0][0]        \n",
            "                                                                 dropout_72[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 32, 32, 32)   18464       concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_82 (ReLU)                 (None, 32, 32, 32)   0           conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_87 (Dropout)            (None, 32, 32, 32)   0           re_lu_82[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 32, 32, 32)   9248        dropout_87[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_83 (ReLU)                 (None, 32, 32, 32)   0           conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_88 (Dropout)            (None, 32, 32, 32)   0           re_lu_83[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 32, 32, 1)    33          dropout_88[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_89 (Dropout)            (None, 32, 32, 1)    0           conv2d_103[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 7,759,521\n",
            "Trainable params: 7,759,521\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "1386/1386 [==============================] - 118s 85ms/step - loss: 7.8897 - mean_absolute_error: 7.8897 - val_loss: 7.5445 - val_mean_absolute_error: 7.5445\n",
            "Epoch 2/10\n",
            "1386/1386 [==============================] - 115s 83ms/step - loss: 6.6284 - mean_absolute_error: 6.6284 - val_loss: 7.3812 - val_mean_absolute_error: 7.3812\n",
            "Epoch 3/10\n",
            "  95/1386 [=>............................] - ETA: 1:41 - loss: 6.4597 - mean_absolute_error: 6.4597"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-bc52e9ac2680>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m denoise_history = denoise_model.fit_generator(generator=denoise_generator, \n\u001b[1;32m     10\u001b[0m                                                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                                                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdenoise_generator_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                                                 )\n\u001b[1;32m     13\u001b[0m   \u001b[0;31m### Saves optimizer and weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training_generator.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "2dKBM4qA8GTw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "After every epoch, the code will generate an external link, this link saves your weights in case of colab disconnecting during training. Example of an epoch:\n",
        "\n",
        "**Epoch 1/1**\n",
        "1797/1797 [==============================] - 48s 27ms/step - loss: 11.4135 - \n",
        "mean_absolute_error: 11.4135 - val_loss: 7.6013 - val_mean_absolute_error: 7.6013 \n",
        "{\"success\":true,\"key\":\"fv9vjj\"\n",
        "\n",
        "\"link\":\"https://file.io/fv9vjj\",\"expiry\":\"14 days\"} **Epoch 1/1**"
      ]
    },
    {
      "metadata": {
        "id": "Ohb6Q94z4yya",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If colab did not disconnect, and you want to save the weights in your local disk, you also can use:\n"
      ]
    },
    {
      "metadata": {
        "id": "rO023FpUwl0F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from hyperopt import Trials, STATUS_OK, tpe\n",
        "from keras.datasets import mnist\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from hyperas import optim\n",
        "from hyperas.distributions import choice, uniform"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nfJbDhxfwnpV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GjAQRnPV47BI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('denoise.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vCfE3xnF8Nfc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Moreover, if you have a model saved from a previous training session, you can upload it to colab and initialize the model's weights with it. \n",
        "\n",
        "You either can use `!wget download_link` or upload the weights from your local disk by using the left panel ('Files' section) in colab.\n",
        "\n",
        "Once the weights are uploaded, you can use\n",
        "\n",
        "> ``denoise_model = keras.models.load_model('./denoise.h5')\n",
        "``\n",
        "\n",
        "to load the weights."
      ]
    },
    {
      "metadata": {
        "id": "e9FzSZzMEcs4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualization of Denoising Results\n",
        "To visualize how the denoised patches look, you can run the following function. It returns the noisy patch, the denoised patch in the middle, and the clean patch in the right side. "
      ]
    },
    {
      "metadata": {
        "id": "XFA_8uN4Eb3B",
        "colab_type": "code",
        "outputId": "acaf8286-99b7-49c1-8551-91420fee2a93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "cell_type": "code",
      "source": [
        "plot_denoise(denoise_model_3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAACmCAYAAABXw78OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqF8dNIcGqUMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "SyABaCvkEPDR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training a Descriptor Network\n",
        "In the last section we trained a model that given a noisy patch, outputs a denoised version of it. We hoped that by doing so, we will improve the performance of the second part, which is training a network that outputs the descriptor. As we mentioned, a descriptor is a numerical vector that represents the small images we have. The dataset consists of a large number of small images, which are cropped patches from other larger images. Hence, they represent some local part of a scene. That is why there are no objects represented, only corners or textures. Each of these patches is related to a subset of other patches of the dataset by some kind of geometric transformation (e.g. rotation).  For a given patch, we want the network to output a vector that is close to the vectors of the patches that represent the same local part of a scene, while being far from patches do not represent that local part of a scene.\n",
        "\n",
        "To do so, we will build a convolutional neural network that takes the input of $32\\times32$ and outputs a descriptor of size $128$. For the loss, we use the triplet loss, which takes an anchor patch, a negative patch and a positive patch. The idea is to train the network so the descriptors from the anchor and positive patch have a low distance between them, and the negative and anchor patch have a large distance between them. \n",
        "\n",
        "In this cell we generate a triplet network, which is a network formed by three copies of the same network. That means that the descriptor model will compute the descriptor for the input `'a'` (anchor), the same descriptor model (with the same weights) will compute the descriptor for the input `'p'` (positive), and again the same model will compute the descriptor for the input `'n'` (negative). "
      ]
    },
    {
      "metadata": {
        "id": "DVmDZIRTHPDa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Lambda\n",
        "shape = (32, 32, 1)\n",
        "xa = Input(shape=shape, name='a')\n",
        "xp = Input(shape=shape, name='p')\n",
        "xn = Input(shape=shape, name='n')\n",
        "descriptor_model = get_descriptor_model(shape)\n",
        "ea = descriptor_model(xa)\n",
        "ep = descriptor_model(xp)\n",
        "en = descriptor_model(xn)\n",
        "\n",
        "loss = Lambda(triplet_loss)([ea, ep, en])\n",
        "\n",
        "descriptor_model_trip = Model(inputs=[xa, xp, xn], outputs=loss)\n",
        "sgd = keras.optimizers.SGD(lr=0.1)\n",
        "descriptor_model_trip.compile(loss='mean_absolute_error', optimizer=sgd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BllXKocHCwZ7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here we use the class HPatches, which loads the corresponding files by using the method `read_image_file`. It reads the patches. The output of read_image_file is a tuple of the form (images, labels), which is passed to the class `DataGeneratorDesc`. This class is a generator that creates batches of triplets, and each epoch is defined by the number of triplets in the argument `num_triplets`.\n",
        "\n",
        "**Updated**: In the previous version of the baseline code, we were training the descriptor model with the noisy patches, not with the denoised ones. By adding the argument `denoise_model=denoise_model` to the class HPatches we can use the denoised images instead to train this descriptor model (if `denoise_model=None`, the noisy patches will be used). However, as it has to compute the denoised patch first, the loading of the data will be slower (6/7 extra min).  If you want to train the model with the clean patches instead, you can set the argument `use_clean=True`. In this last case, even if a denoise model is given, it will not be used. When running this piece of code **the type of patches (denoised, noisy or clean) used is printed**."
      ]
    },
    {
      "metadata": {
        "id": "YIR1cH4fDwKj",
        "colab_type": "code",
        "outputId": "3b45f33f-6c3c-46fe-b080-10820ca03277",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "cell_type": "code",
      "source": [
        "### Descriptor loading and training\n",
        "# Loading images\n",
        "hPatches = HPatches(train_fnames=train_fnames, test_fnames=test_fnames,\n",
        "                    denoise_model=denoise_model, use_clean=False)\n",
        "# Creating training generator\n",
        "training_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=1), num_triplets=100000)\n",
        "# Creating validation generator\n",
        "val_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=0), num_triplets=10000)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using denoised patches\n",
            "100%|██████████| 116/116 [00:30<00:00,  3.82it/s]\n",
            "Denoising patches...\n",
            "100%|██████████| 15589/15589 [04:11<00:00, 61.89it/s]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100000/100000 [00:01<00:00, 61229.90it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using denoised patches\n",
            "100%|██████████| 116/116 [00:18<00:00,  2.26it/s]\n",
            "Denoising patches...\n",
            "100%|██████████| 9525/9525 [02:32<00:00, 62.45it/s]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:00<00:00, 59558.89it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "GoQYyuD7_4PS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We plot a random triplet in the form of anchor, positive and negative sample. The positive and anchor patches are similar between them (the difference is a geometric transformation, for example rotation), whereas the negative sample should be quite dissimilar to any of the other two."
      ]
    },
    {
      "metadata": {
        "id": "3RQmOMU92csu",
        "colab_type": "code",
        "outputId": "d6b2c34d-bd97-4e33-fccf-00204ce969aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "cell_type": "code",
      "source": [
        "plot_triplet(training_generator)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAACmCAYAAABXw78OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "UaE2_6HUCAOw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We now train the descriptor model and save the weights afterward."
      ]
    },
    {
      "metadata": {
        "id": "jvIbHpHMXWbh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'val_mean_absolute_error', 'loss', 'mean_absolute_error', 'val_loss']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QPyc8as42WTQ",
        "colab_type": "code",
        "outputId": "75bf8595-5d31-4be4-a723-6e3f48239cbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "### As with the denoising model, we use a loop to save for each epoch \n",
        "## #the weights in an external website in case colab stops. \n",
        "### reset, so e.g. calling 5 times fit(epochs=1) behave as fit(epochs=5)\n",
        "\n",
        "### If you have a model saved from a previous training session\n",
        "### Load it in the next line\n",
        "# descriptor_model_trip.set_weights(keras.models.load_model('./descriptor.h5').get_weights())\n",
        "# descriptor_model_trip.optimizer = keras.models.load_model('./descriptor.h5').optimizer\n",
        "\n",
        "  \n",
        "descriptor_history = descriptor_model_trip.fit_generator(generator=training_generator, epochs=1, verbose=1, validation_data=val_generator)\n",
        "  \n",
        "  ### Saves optimizer and weights\n",
        "descriptor_model_trip.save('descriptor.h5') \n",
        "  ### Uploads files to external hosting\n",
        "!curl -F \"file=@descriptor.h5\" https://file.io\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "1999/2000 [============================>.] - ETA: 0s - loss: 0.2211"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100000/100000 [00:03<00:00, 27102.66it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 158s 79ms/step - loss: 0.2211 - val_loss: 0.2615\n",
            "{\"success\":true,\"key\":\"Qdk7Iw\",\"link\":\"https://file.io/Qdk7Iw\",\"expiry\":\"14 days\"}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GM59v5nToFWK",
        "colab_type": "code",
        "outputId": "2399f1a5-f53b-4795-9fe4-043afbac8de6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "cell_type": "code",
      "source": [
        "plot_history(descriptor_history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAFnCAYAAAC7EwBkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "iqcg4BHE9RpK",
        "colab_type": "code",
        "outputId": "83cec68a-d252-4efa-aef7-0c9a3bb4e766",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "cell_type": "code",
      "source": [
        "descriptor_model_trip.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "a (InputLayer)                  (None, 32, 32, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "p (InputLayer)                  (None, 32, 32, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "n (InputLayer)                  (None, 32, 32, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       (None, 128)          1336928     a[0][0]                          \n",
            "                                                                 p[0][0]                          \n",
            "                                                                 n[0][0]                          \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 1)            0           sequential_1[1][0]               \n",
            "                                                                 sequential_1[2][0]               \n",
            "                                                                 sequential_1[3][0]               \n",
            "==================================================================================================\n",
            "Total params: 1,336,928\n",
            "Trainable params: 1,336,032\n",
            "Non-trainable params: 896\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rzkkYNRFopsU",
        "colab_type": "code",
        "outputId": "3124f398-56b5-4e63-9737-8d8d38b76518",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "descriptor_history.history.keys()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['loss', 'val_loss']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "metadata": {
        "id": "NJ-r9D4hDxij",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generating descriptors files for test data \n",
        "\n",
        "To evaluate the performance of out model we will use an existing evaluation code, which is called HPatches benchmark. HPatches benchmark takes as input the descriptors for the test data in a CSV form. So the whole pipeline is represented in the following image.\n",
        "\n",
        "![](https://i.ibb.co/WcDDf3q/Screenshot-from-2019-02-15-11-17-24.png)\n",
        "\n",
        "This function generates those files by passing it a descriptor model and a denoising model. It performs a first step of denoising the patches, and a second one of computing the descriptor of the denoised patch. If no denoising model is given (variable set to `None`), the descriptor is computed directly in the noisy patch.\n",
        "\n",
        "Similarly to the loading data part, you have the denoise_model variable and `use_clean` variable. If `use_clean` is set to True, the CSV generated will be those of the clean patches, even if a denoising model is given. If set to False, then depends on the variable `denoise_model`. If there is no denoise model (`denoise_model=None`), then it will use the noisy patches. If you give a denoising model, then it will compute the CSV for the denoised patches. This can be useful to explore different scenarios (for example, the Upper Bound can be training the descriptor network with clean patches, and testing with clean patches), however you should always report the score when using noisy patches (depending on the approach you develop, you may want to denoise them or not). The official baseline uses the denoised patches. "
      ]
    },
    {
      "metadata": {
        "id": "kiJb2XDG9bsJ",
        "colab_type": "code",
        "outputId": "1969acf2-f50b-4962-8371-6c286bacc7f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "generate_desc_csv(descriptor_model, seqs_test, denoise_model=denoise_model, use_clean=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [06:38<00:00, 12.03s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "s0jFr05rE1oI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluating descriptors in HPatches Benchmark\n",
        "We use HPatches benchmark code to compute the results for our model. \n",
        "\n",
        "**Updated**: The necessary code is included in the repository we cloned at the beginning of the code, so we do not need to download any extra data. Also, we simplified the results, so now they only return one value for each of the three tasks."
      ]
    },
    {
      "metadata": {
        "id": "YvOGRh3sc9Wo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we will perform the evaluation of three different tasks (Verification, Matching and Evaluation) using the CSV files we generated as input and the `hpatches_eval.py` script. We also print the results using the `hpatches_results.py` script. The scripts will return a score for each of the tasks. The metric used is called mean Average Precision, which it uses the Precision of the model. The Precision is defined, for a given number of retrieved elements, as the ratio of correct retrieved elements / number of retrieved elements. [Link to Wikipedia with Precision explanation](https://en.wikipedia.org/wiki/Precision_and_recall). The definition of the three different tasks is taken from the [HPatches paper](https://arxiv.org/pdf/1704.05939.pdf).\n",
        "\n",
        "In all of the tasks if you use the optional argument `--more_info` in `hpatches_results.py` you can see extra mAP information. However, the important score is the mAP score reported without this flag.\n",
        "\n",
        "### Verification\n",
        "\n",
        "Patch verification measures the ability of a descriptor to classify whether two patches are extracted from the same measurement. Now we compute the score of our architecture in this task.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Awnyv4xTYSFH",
        "colab_type": "code",
        "outputId": "55bd73d4-f205-4891-b76e-3aca4c2c80a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        }
      },
      "cell_type": "code",
      "source": [
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=verification --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=verification\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            ">> Running HPatch evaluation for \u001b[34mcustom\u001b[0m\n",
            ">> Please wait, loading the descriptor files...\n",
            ">> Descriptor files loaded.\n",
            ">> Evaluating \u001b[32mverification\u001b[0m task\n",
            "Processing verification task 1/3 : 100% 1000000/1000000 [01:34<00:00, 10582.67it/s]\n",
            "Processing verification task 2/3 : 100% 1000000/1000000 [01:39<00:00, 10041.76it/s]\n",
            "Processing verification task 3/3 : 100% 1000000/1000000 [01:41<00:00, 9834.83it/s]\n",
            ">> \u001b[32mVerification\u001b[0m task finished in 305 secs  \n",
            "\u001b[32mVerification\u001b[0m task results:\n",
            "Mean Average Precision is 0.688231\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5290Bw-udJdr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Matching\n",
        "Image matching, tests to what extent a descriptor can correctly identify correspondences in two images."
      ]
    },
    {
      "metadata": {
        "id": "EUqpwi87ckJv",
        "colab_type": "code",
        "outputId": "bd5ad48c-a188-4bb3-8ada-f9fd84e224df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        }
      },
      "cell_type": "code",
      "source": [
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=matching --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=matching\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            ">> Running HPatch evaluation for \u001b[34mcustom\u001b[0m\n",
            ">> Please wait, loading the descriptor files...\n",
            ">> Descriptor files loaded.\n",
            ">> Evaluating \u001b[32mmatching\u001b[0m task\n",
            "100% 40/40 [02:12<00:00,  4.47s/it]\n",
            ">> \u001b[32mMatching\u001b[0m task finished in 132 secs  \n",
            "\u001b[32mMatching\u001b[0m task results:\n",
            "Mean Average Precision is 0.106473\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RXXgbN7DdMnx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Retrieval\n",
        "Retrieval tests how well a descriptor can match a query patch to a pool of patches extracted from many images."
      ]
    },
    {
      "metadata": {
        "id": "ZNmKIat1cn_M",
        "colab_type": "code",
        "outputId": "73485401-41e7-4116-a7a7-baefadf436af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "cell_type": "code",
      "source": [
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=retrieval --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=retrieval"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            ">> Running HPatch evaluation for \u001b[34mcustom\u001b[0m\n",
            ">> Please wait, loading the descriptor files...\n",
            ">> Descriptor files loaded.\n",
            ">> Evaluating \u001b[32mretrieval\u001b[0m task\n",
            ">> Please wait, computing distance matrix...\n",
            "tcmalloc: large alloc 1600004096 bytes == 0x562e3d568000 @  0x7f58832561e7 0x7f5878e57cf1 0x7f5878eba3a2 0x7f5878ebc0de 0x7f5878f530e8 0x562e1724dfe5 0x562e17243d0a 0x562e1724b5fe 0x562e1724b232 0x562e17243d0a 0x562e1724bc38 0x562e17243d0a 0x562e17243629 0x562e1727461f 0x562e1726f322 0x562e1726e67d 0x562e1721d1ab 0x7f5882e53b97 0x562e1721ca2a\n",
            ">> Distance matrix done.\n",
            "Processing retrieval task: 100% 10000/10000 [04:01<00:00, 42.11it/s]\n",
            ">> \u001b[32mRetrieval\u001b[0m task finished in 272 secs  \n",
            "\u001b[32mRetrieval\u001b[0m task results:\n",
            "Mean Average Precision is 0.350799\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8_2fBzUB5RF2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Compressing and saving the CSV files \n",
        "\n",
        "This is not necessary for the analysis of the baseline code included in the report. However, we will be hosting a competition in an external website to see who can achieve the highest score. In that case, you will need to submit the CSV files, as the scoring script will be performed in an external server. With that aim, we include here a way to save the files either in your local disc or in your google drive account.\n",
        "\n",
        "We first compress the directory with all the CSV by using the following command. Remove the `q` option if you want it to output the progress."
      ]
    },
    {
      "metadata": {
        "id": "Lh_svT3p5Ww-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!zip -rq descriptors.zip ./out/custom"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "svoL779J8AJK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The generated .zip is quite large, the method we used for the weights does not work. We have two other methods. First, in the file explorer in the left column we can right-click in the file and then click download. Then, we will see a circle next to the file showing the download progress.\n",
        "\n",
        "The second way does not require for you to download the files, it save the zip file in your Google Drive account, and you can download it later to your machine if you want. To do so, follow this method (found [here](https://stackoverflow.com/questions/49428332/how-to-download-large-files-like-weights-of-a-model-from-colaboratory)). First run the next cell, and the output will be a link for authentication purposes, and just follow the instructions"
      ]
    },
    {
      "metadata": {
        "id": "RjOmPv5z7Opx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "def save_file_to_drive(name, path):\n",
        "  file_metadata = {\n",
        "    'name': name,\n",
        "    'mimeType': 'application/octet-stream'\n",
        "  }\n",
        "\n",
        "  media = MediaFileUpload(path, \n",
        "                          mimetype='application/octet-stream',\n",
        "                          resumable=True)\n",
        "\n",
        "  created = drive_service.files().create(body=file_metadata,\n",
        "                                  media_body=media,\n",
        "                                  fields='id').execute()\n",
        "\n",
        "  print('File ID: {}'.format(created.get('id')))\n",
        "\n",
        "  return created\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YfzjfMc59NKm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we can use the following function to save the file to your drive account. The second argument is the name of the file we want to save, and the first argument the name that will have in your Drive."
      ]
    },
    {
      "metadata": {
        "id": "UwrqWr_c7pAi",
        "colab_type": "code",
        "outputId": "005994a0-bb3c-4c8d-dc93-91fdd94a4e98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "save_file_to_drive('descriptors_save.zip', 'descriptors.zip')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ID: 1dHq0eDqoLMMmr6YOexZOU6cLwhFJYgH8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{u'id': u'1dHq0eDqoLMMmr6YOexZOU6cLwhFJYgH8'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    }
  ]
}